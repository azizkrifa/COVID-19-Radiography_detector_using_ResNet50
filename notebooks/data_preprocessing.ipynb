{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-1",
   "metadata": {},
   "source": [
    "# COVID-19 Radiography Dataset Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-download",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Imports and Setup\n",
    "\n",
    "- `kagglehub`: For downloading datasets from Kaggle.\n",
    "- `shutil`: Utilities for file operations like copying and removing files.\n",
    "- `pathlib.Path`: For handling filesystem paths in a platform-independent way.\n",
    "- `splitfolders`: To split datasets into train, validation, and test folders.\n",
    "- `os`: Operating system utilities for directory and file management.\n",
    "- `tensorflow.keras.preprocessing.image`: For image loading and augmentation.\n",
    "- `utils.display_data_distribution`: Custom utility function to visualize data distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41700ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import splitfolders\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from utils import display_data_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708238e1",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "## ðŸ“‚ Dataset Downloader\n",
    "\n",
    "This script downloads and prepares the **COVID-19 Radiography Database** for training a COVID detector model.  \n",
    "It retrieves the dataset from Kaggle, organizes the images by class, and saves them in a structured directory:\n",
    "\n",
    "1. Download the dataset from Kaggle using `kagglehub.dataset_download`.\n",
    "2. Set the `DATA_DIR` variable to your desired storage location:\n",
    "   - Leave it empty to use the current working directory.\n",
    "   - In Google Colab, mount Google Drive and set the path accordingly.\n",
    "3. The script will copy images into a new folder named `data_for_split` with the following structure:\n",
    "\n",
    "```bash\n",
    "   data_for_split/\n",
    "         â”œâ”€â”€ COVID/\n",
    "         â”œâ”€â”€ Normal/\n",
    "         â”œâ”€â”€ Lung_Opacity/\n",
    "         â””â”€â”€ Viral Pneumonia/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776989cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "src_path = kagglehub.dataset_download(\"tawsifurrahman/covid19-radiography-database\")\n",
    "print(\"Original path:\", src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51472f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"\" # Change this to your local path or Google Drive mount path if running in Colab !!!\n",
    "              # if you keep DATA_DIR = \"\" , the data will be loaded in your current repo !!\n",
    "\n",
    "with open('Shared_vars.py', 'w') as f:\n",
    "    f.write(f\"DATA_DIR=\\\"{DATA_DIR}\\\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc93915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "source_root = Path(src_path+'/COVID-19_Radiography_Dataset')\n",
    "target_root = Path(DATA_DIR + \"/data_for_split\")\n",
    "\n",
    "# Class folders\n",
    "classes = [\"COVID\", \"Normal\", \"Lung_Opacity\", \"Viral Pneumonia\"]\n",
    "\n",
    "# Create image-only dataset\n",
    "for cls in classes:\n",
    "    source = source_root / cls / \"images\"\n",
    "    target = target_root / cls\n",
    "    target.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for file in source.glob(\"*.*\"):\n",
    "        shutil.copy(file, target)\n",
    "\n",
    "print(\"âœ… Images copied successfully to\", target_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-splitting",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## âš–ï¸ Split into train, validation, and test sets\n",
    "\n",
    "The dataset is split using a ratio of:\n",
    "- 70% for training\n",
    "- 20% for validation\n",
    "- 10% for testing\n",
    "- The final structure will be:\n",
    "\n",
    "```bash\n",
    "    dataset/\n",
    "        â”œâ”€â”€ train/\n",
    "        â”‚     â”œâ”€â”€ COVID/\n",
    "        â”‚     â”œâ”€â”€ Normal/\n",
    "        â”‚     â”œâ”€â”€ Lung_Opacity/\n",
    "        â”‚     â””â”€â”€ Viral Pneumonia/\n",
    "        â”œâ”€â”€ val/\n",
    "        â”‚     â”œâ”€â”€ COVID/\n",
    "        â”‚     â”œâ”€â”€ Normal/\n",
    "        â”‚     â”œâ”€â”€ Lung_Opacity/\n",
    "        â”‚     â””â”€â”€ Viral Pneumonia/\n",
    "        â””â”€â”€ test/\n",
    "              â”œâ”€â”€ COVID/\n",
    "              â”œâ”€â”€ Normal/\n",
    "              â”œâ”€â”€ Lung_Opacity/\n",
    "              â””â”€â”€ Viral Pneumonia/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = f\"{DATA_DIR}/dataset\"\n",
    "\n",
    "splitfolders.ratio(\n",
    "    f\"{DATA_DIR}/data_for_split\",\n",
    "    output=base_dir,\n",
    "    seed=42,\n",
    "    ratio=(.7, .2, .1),  # train, val, test\n",
    "    group_prefix=None  # Only needed for paired data like images + masks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divider-4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "class-distribution",
   "metadata": {},
   "source": [
    "## ðŸ“Š View Training Data Distribution\n",
    "\n",
    "After splitting the dataset, you can check the distribution of images across classes in the training set.  \n",
    "This helps ensure the dataset is balanced before starting model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd108b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = base_dir + \"/train\"\n",
    "display_data_distribution(train_dir)  # Display the distribution of images across classes in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-imbalance-note",
   "metadata": {},
   "source": [
    "**Observation:** There is significant class imbalance in the training set. We will address this with data augmentation in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae4b05",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ˆ Data Augmentation\n",
    "\n",
    "To increase dataset diversity and improve model generalization, **data augmentation** is applied to selected classes.  \n",
    "\n",
    "#### ðŸ“‚ Augmentation Process\n",
    "- All original images from the training set are copied into a new folder: **train_augmented**.  \n",
    "- The classes **COVID**, **Lung_Opacity**, and **Viral Pneumonia** are augmented to balance the dataset.  \n",
    "- For each original image in these classes, **3 augmented versions** are generated.  \n",
    "\n",
    "#### ðŸ“Š Example Output\n",
    "After augmentation, the new class distribution in the training set is displayed, helping verify dataset balance before training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aug_dir = base_dir + \"/train_augmented\"\n",
    "\n",
    "classes_to_augment = ['COVID', 'Lung_Opacity', 'Viral Pneumonia'] \n",
    "\n",
    "# Create augmentation generator\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Copy all original images to the new folder\n",
    "for cls in os.listdir(train_dir):\n",
    "    src = os.path.join(train_dir, cls)\n",
    "    dst = os.path.join(aug_dir, cls)\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "\n",
    "    for img_name in os.listdir(src):\n",
    "        shutil.copy(os.path.join(src, img_name), os.path.join(dst, img_name))\n",
    "\n",
    "        # Augment only if class is in the selected list\n",
    "        if cls in classes_to_augment:\n",
    "            img = load_img(os.path.join(src, img_name))\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            # Create 3 augmented versions\n",
    "            for i, batch in enumerate(augmenter.flow(x, batch_size=1,\n",
    "                                                     save_to_dir=dst,\n",
    "                                                     save_prefix='aug',\n",
    "                                                     save_format='jpeg')):\n",
    "                if i >= 3:\n",
    "                    break\n",
    "\n",
    "display_data_distribution(aug_dir) # Display augmented data distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
